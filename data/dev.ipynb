{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34341da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datasets\n",
    "import random\n",
    "import soundfile as sf\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ed9aa",
   "metadata": {},
   "source": [
    "# StressTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a04b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset(\"slprl/StressTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231d705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = ds['test'][0]['audio'].get_all_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a984ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioSamples:\n",
       "  data (shape): torch.Size([1, 58112])\n",
       "  pts_seconds: 0.0\n",
       "  duration_seconds: 3.632\n",
       "  sample_rate: 16000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][0]['audio'].get_all_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe53e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51a3ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stresstest/stresstest.jsonl', 'w') as f:\n",
    "    for data in ds['test']:\n",
    "        f.write(\n",
    "            json.dumps({\n",
    "                'transcription': data['transcription'],\n",
    "                'description': data['description'],\n",
    "                'intonation': data['intonation'],\n",
    "                'metadata': data['metadata'],\n",
    "                'stress_pattern': data['stress_pattern'],\n",
    "            }) + '\\n'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56de68bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acc86535",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(ds['test']):\n",
    "    random_prompt_idx = random.randint(0, len(ds['test']) - 1)\n",
    "    prompt_audio = ds['test'][random_prompt_idx]['audio'].get_all_samples()\n",
    "    sf.write('stresstest/prompt/audio_{}.wav'.format(idx), prompt_audio.data.numpy()[0], prompt_audio.sample_rate)\n",
    "    ground_truth_audio = data['audio'].get_all_samples()\n",
    "    sf.write('stresstest/ground_truth/audio_{}.wav'.format(idx), ground_truth_audio.data.numpy()[0], ground_truth_audio.sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951be832",
   "metadata": {},
   "source": [
    "# ParaSpeechCaps Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1857f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df21b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c31612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21ace02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5fe86baed1485687732a91fa429724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3698ea9199448bad198260ad2c2ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_scaled-00000-of-00002.parquet:   0%|          | 0.00/161M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3c9e94213447a09787e8e562f2ae78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_scaled-00001-of-00002.parquet:   0%|          | 0.00/161M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589f8b1559e54a28a614b108c66e0989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_base-00000-of-00001.parquet:   0%|          | 0.00/37.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b00e1b3cad4b7190a0c8c88af40972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/dev-00000-of-00001.parquet:   0%|          | 0.00/3.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc337e95dc14207b532f2d2b1add4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/holdout-00000-of-00001.parquet:   0%|          | 0.00/4.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4675947d98a48daa589ea3cc260b18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_scaled split:   0%|          | 0/924651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e473797556f44a65a2269a75b530d571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_base split:   0%|          | 0/116516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c57391a9ac74a84a56355b6ee053715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/11967 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779032c4f6ad4b44abb5ce1b785193f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating holdout split:   0%|          | 0/14756 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "holdout = datasets.load_dataset(\"ajd12342/paraspeechcaps\", split=\"holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd95c797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'voxceleb',\n",
       " 'relative_audio_path': 'voxceleb2/dev/aac/id05998/WNpiaa_BtEc/00264_voicefixer.wav',\n",
       " 'text_description': [' A Scottish male speaks with clear enunciation and a low-pitched, deep voice. His speech is delivered at a measured speed, and the environment in which the recording was made allows for balanced clarity.'],\n",
       " 'transcription': \" Two separate things. Well, three, actually. You've talked about disability and you've talked about welfare.\",\n",
       " 'intrinsic_tags': ['deep', 'enunciated', 'scottish'],\n",
       " 'situational_tags': None,\n",
       " 'basic_tags': ['environment balanced in clarity',\n",
       "  'low-pitched',\n",
       "  'male',\n",
       "  'measured speed'],\n",
       " 'all_tags': ['deep',\n",
       "  'enunciated',\n",
       "  'environment balanced in clarity',\n",
       "  'low-pitched',\n",
       "  'male',\n",
       "  'measured speed',\n",
       "  'scottish'],\n",
       " 'speakerid': 'id05998',\n",
       " 'name': 'Michael Gove',\n",
       " 'duration': 5.6,\n",
       " 'gender': 'male',\n",
       " 'accent': 'scottish',\n",
       " 'pitch': 'low-pitched',\n",
       " 'speaking_rate': 'measured speed',\n",
       " 'noise': 'environment balanced in clarity',\n",
       " 'utterance_pitch_mean': 118.15841674804688,\n",
       " 'snr': 44.7011833190918,\n",
       " 'phonemes': \" tu sɛpɜ˞eɪt θɪŋz. wɛl, θɹi, æktʃuʌli. ju'vi tɔkt ʌbaʊt dɪsʌbɪlɪti ʌnd ju'vi tɔkt ʌbaʊt wɛlfɛɹ.\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30ef291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = set([\n",
    "    \"enthusiastic\",\n",
    "    \"happy\",\n",
    "    \"angry\",\n",
    "    \"saddened\",\n",
    "    \"awed\",\n",
    "    \"calm\",\n",
    "    \"anxious\",\n",
    "    \"disgusted\",\n",
    "    \"scared\",\n",
    "    \"confused\",\n",
    "    \"bored\",\n",
    "    \"sleepy\",\n",
    "    \"pained\",\n",
    "    \"guilt\",\n",
    "    \"sarcastic\",\n",
    "    \"sympathetic\",\n",
    "    \"admiring\",\n",
    "    \"desirous\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5de3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_data = []\n",
    "for data in holdout:\n",
    "    for tag in data['all_tags']:\n",
    "        if tag in emotions:\n",
    "            usable_data.append(\n",
    "                {\n",
    "                    'transcription': data['transcription'],\n",
    "                    'emotion': tag,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9736af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paraspeechcaps_holdout.jsonl', 'w') as f:\n",
    "    for data in usable_data:\n",
    "        f.write(\n",
    "            json.dumps(data) + '\\n'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e807b",
   "metadata": {},
   "source": [
    "# Expresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a174a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/data/group_data/li_lab/siqiouya/datasets/expresso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a829bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dirname, 'splits/test.txt'), 'r') as f:\n",
    "    test_files = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a67d8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dirname, 'splits/train.txt'), 'r') as f:\n",
    "    train_files = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c796085",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2transcription = {}\n",
    "with open(os.path.join(dirname, 'read_transcriptions.txt'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        id, transcription = line.strip().split('\\t')\n",
    "        id2transcription[id] = transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7fe031",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('expresso', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bdc389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_emotions = ['default', 'happy', 'sad']\n",
    "expresso_data = []\n",
    "for file in test_files[1:]:\n",
    "    if len(file.split('\\t')) == 1:\n",
    "        items = file.split('_')\n",
    "        speaker = items[0]\n",
    "        emotion = items[1]\n",
    "        if emotion not in candidate_emotions:\n",
    "            continue\n",
    "        emphasis = len(items) == 4 and items[2] == 'emphasis'\n",
    "        audio_path = os.path.join(dirname, 'audio_48khz/read', speaker, emotion, 'base', file + '.wav')\n",
    "        audio, sample_rate = sf.read(audio_path)\n",
    "        sf.write('expresso/ground_truth/audio_{}.wav'.format(len(expresso_data)), audio, sample_rate)\n",
    "        expresso_data.append({\n",
    "            'id': file,\n",
    "            'speaker': speaker,\n",
    "            'emotion': emotion,\n",
    "            'emphasis': emphasis,\n",
    "            'transcription': id2transcription[file],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "031f3f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ex01_default_00358',\n",
       " 'speaker': 'ex01',\n",
       " 'emotion': 'default',\n",
       " 'emphasis': False,\n",
       " 'transcription': \"Karen's in Switzerland?\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expresso_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4152fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_emotion_emphasis_to_file = defaultdict(list)\n",
    "for file in train_files[1:]:\n",
    "    if len(file.split('\\t')) == 1:\n",
    "        items = file.split('_')\n",
    "        speaker = items[0]\n",
    "        emotion = items[1]\n",
    "        if emotion not in candidate_emotions:\n",
    "            continue\n",
    "        emphasis = len(items) == 4 and items[2] == 'emphasis'\n",
    "        speaker_emotion_emphasis_to_file[(speaker, emotion, emphasis)].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cb39f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(expresso_data):\n",
    "    speaker, emotion, emphasis = data['speaker'], data['emotion'], data['emphasis']\n",
    "    \n",
    "    while True:\n",
    "        data['prompt_id'] = random.choice(speaker_emotion_emphasis_to_file[(speaker, emotion, emphasis)])\n",
    "        file = data['prompt_id']\n",
    "        audio_path = os.path.join(dirname, 'audio_48khz/read', speaker, emotion, 'base', file + '.wav')\n",
    "        if os.path.exists(audio_path):\n",
    "            break\n",
    "    audio, sample_rate = sf.read(audio_path)\n",
    "    sf.write('expresso/prompt/audio_{}.wav'.format(idx), audio, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4675297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('expresso/expresso.jsonl', 'w') as f:\n",
    "    for data in expresso_data:\n",
    "        f.write(\n",
    "            json.dumps(data) + '\\n'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e536a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expressive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
